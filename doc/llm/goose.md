# Goose

https://block.github.io/goose/

- Open Source
Built with transparency and collaboration in mind, goose empowers developers to contribute, customize, and innovate freely.

- Runs Locally
Goose runs locally to execute tasks efficiently, keeping control in your hands.

- Extensible
Customize goose with your preferred LLM and enhance its capabilities by connecting it to any external MCP server or API.

- Autonomous
Goose independently handles complex tasks, from debugging to deployment, freeing you to focus on what matters most.



https://github.com/block/goose


an open-source, extensible **AI agent** that goes beyond code suggestions
install, execute, edit, and test with any LLM




# providers


https://block.github.io/goose/docs/getting-started/providers


Check:
Ollama	Local model runner supporting Qwen, Llama, DeepSeek, and other open-source models. Because this provider runs locally, you must first download and run a model.

Ollama provides open source LLMs, such as DeepSeek-r1, that you can install and run locally. Note that the native DeepSeek-r1 model doesn't support tool calling, however, we have a custom model you can use with Goose.

warning
Note that this is a 70B model size and requires a powerful device to run smoothly.

Download and install Ollama from ollama.com.
In a terminal window, run the following command to install the custom DeepSeek-r1 model:


ollama run michaelneale/deepseek-r1-goose



# Extensions

https://block.github.io/goose/docs/getting-started/using-extensions/




## Manage Goose Sessions
https://block.github.io/goose/docs/guides/managing-goose-sessions/ 
